# Deploy KV service to ACI via Terraform, upload test deltas, verify getValues.
# Terraform creates resource group, storage account, file share, and ACI; data is uploaded after ACI is up.

name: KV test

permissions:
  contents: read
  id-token: write

on:
  workflow_dispatch:
    inputs:
      region:
        description: 'Azure region for all resources'
        required: false
        type: string
        default: 'centralindia'
      kv_image:
        description: 'KV service container image'
        required: false
        type: string
        default: 'ispirt.azurecr.io/depainferencing/azure/key-value-service:nonprod-1.2.0.4'
env:
  DELTAS_PATH: deltas   # subdirectory in share fslogix = /data/deltas in container

jobs:
  deploy-and-test:
    runs-on: ubuntu-22.04
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_AKS_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_AKS_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_AKS_SUBSCRIPTION_ID }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Terraform Init (KV ACI)
        working-directory: deployment-scripts/azure/kv
        run: terraform init

      - name: Terraform Apply
        working-directory: deployment-scripts/azure/kv
        run: |
          terraform apply -auto-approve \
            -var="location=${{ inputs.region }}" \
            -var="kv_image=${{ inputs.kv_image }}"

      - name: Get ACI IP and name
        id: aci
        working-directory: deployment-scripts/azure/kv
        run: |
          IP=$(terraform output -raw aci_ip_address)
          ACI_NAME=$(terraform output -raw aci_name)
          echo "ip=$IP" >> $GITHUB_OUTPUT
          echo "aci_name=$ACI_NAME" >> $GITHUB_OUTPUT
          echo "KV service IP: $IP (name: $ACI_NAME)"

      - name: Get storage key and share name for upload
        id: tf_outputs
        working-directory: deployment-scripts/azure/kv
        run: |
          KEY=$(terraform output -raw storage_primary_key)
          SHARE=$(terraform output -raw file_share_name)
          SA_NAME=$(terraform output -raw storage_account_name)
          echo "storage_primary_key=$KEY" >> $GITHUB_OUTPUT
          echo "file_share_name=$SHARE" >> $GITHUB_OUTPUT
          echo "storage_account_name=$SA_NAME" >> $GITHUB_OUTPUT
          echo "::add-mask::$KEY"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install KV test dependencies
        run: |
          pip install -r tools/key-value-service/requirements-test.txt

      - name: Generate and upload first delta (Python)
        working-directory: ./tools/key-value-service
        env:
          KV_STORAGE_ACCOUNT: ${{ steps.tf_outputs.outputs.storage_account_name }}
          KV_STORAGE_KEY: ${{ steps.tf_outputs.outputs.storage_primary_key }}
          KV_SHARE_NAME: ${{ steps.tf_outputs.outputs.file_share_name }}
          KV_SHARE_PATH: ${{ env.DELTAS_PATH }}
        run: |
          echo "::add-mask::$KV_STORAGE_KEY"
          python generate_and_upload_delta.py --csv data.csv --delta-name DELTA_0000000000000001

      - name: Wait for KV to load data
        run: |
          echo "Waiting 90s for KV service to start and load deltas..."
          sleep 90

      - name: Run KV Python tests (initial load)
        env:
          KV_BASE_URL: http://${{ steps.aci.outputs.ip }}:51052
          KV_TEST_HOSTNAME: test.com
        run: |
          cd tools/key-value-service && python -m pytest tests/test_getvalues.py -v

      - name: Generate and upload second delta (Python)
        working-directory: ./tools/key-value-service
        env:
          KV_STORAGE_ACCOUNT: ${{ steps.tf_outputs.outputs.storage_account_name }}
          KV_STORAGE_KEY: ${{ steps.tf_outputs.outputs.storage_primary_key }}
          KV_SHARE_NAME: ${{ steps.tf_outputs.outputs.file_share_name }}
          KV_SHARE_PATH: ${{ env.DELTAS_PATH }}
        run: |
          echo "::add-mask::$KV_STORAGE_KEY"
          python generate_and_upload_delta.py --csv tests/data_delta2.csv --delta-name DELTA_0000000000000002

      - name: Wait for KV to reload second delta
        run: |
          echo "Waiting 90s for KV to pick up second delta..."
          sleep 90

      - name: Run KV Python tests (incremental / second delta)
        env:
          KV_BASE_URL: http://${{ steps.aci.outputs.ip }}:51052
          KV_TEST_HOSTNAME: test.com
          KV_TEST_STORAGE_ACCOUNT: ${{ steps.tf_outputs.outputs.storage_account_name }}
          KV_TEST_STORAGE_KEY: ${{ steps.tf_outputs.outputs.storage_primary_key }}
          KV_TEST_SHARE_NAME: ${{ steps.tf_outputs.outputs.file_share_name }}
          KV_TEST_SHARE_PATH: ${{ env.DELTAS_PATH }}
          KV_TEST_RELOAD_WAIT_SEC: "30"
        run: |
          cd tools/key-value-service && python -m pytest tests/test_getvalues_incremental.py -v

      - name: Get container logs
        if: always()
        working-directory: deployment-scripts/azure/kv
        run: |
          echo "=== KV container logs (including if container terminated) ==="
          RG=$(terraform output -raw resource_group_name 2>/dev/null) || true
          if [ -n "$RG" ]; then
            az container logs \
              --resource-group "$RG" \
              --name "${{ steps.aci.outputs.aci_name }}" \
              --tail 500 \
              || true
          else
            echo "Could not get resource group name (Terraform state may be gone)."
          fi

      - name: Empty share dirs before destroy
        if: always()
        working-directory: deployment-scripts/azure/kv
        env:
          STORAGE_KEY: ${{ steps.tf_outputs.outputs.storage_primary_key }}
          SHARE: ${{ steps.tf_outputs.outputs.file_share_name }}
        run: |
          if [ -z "$STORAGE_KEY" ] || [ -z "$SHARE" ]; then
            echo "Skipping (no storage key or share name from Terraform output)."
            exit 0
          fi
          SA_NAME=$(terraform output -raw storage_account_name 2>/dev/null) || true
          [ -z "$SA_NAME" ] && echo "Skipping (no Terraform state)." && exit 0
          echo "::add-mask::$STORAGE_KEY"
          for dir in deltas realtime; do
            names=$(az storage file list --share-name "$SHARE" --path "$dir" --account-name "$SA_NAME" --account-key "$STORAGE_KEY" -o tsv --query "[].name" 2>/dev/null) || true
            for name in $names; do
              [ -n "$name" ] && az storage file delete --share-name "$SHARE" --path "$dir/$name" --account-name "$SA_NAME" --account-key "$STORAGE_KEY" || true
            done
          done

      - name: Terraform Destroy (all resources)
        if: always()
        working-directory: deployment-scripts/azure/kv
        run: |
          terraform destroy -auto-approve \
            -var="location=${{ inputs.region }}" \
            -var="kv_image=${{ inputs.kv_image }}" || true
