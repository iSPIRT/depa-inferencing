# Deploy KV service to ACI via Terraform, upload test deltas, verify getValues.
# Terraform creates resource group, storage account, file share, and ACI; data is uploaded after ACI is up.

name: KV test

permissions:
  contents: read
  id-token: write

on:
  workflow_dispatch:
    inputs:
      region:
        description: 'Azure region for all resources'
        required: false
        type: string
        default: 'centralindia'
      kv_image:
        description: 'KV service container image'
        required: false
        type: string
        default: 'ispirt.azurecr.io/depainferencing/azure/key-value-service:nonprod-1.2.0.4'
env:
  DELTAS_PATH: deltas   # subdirectory in share fslogix = /data/deltas in container

jobs:
  deploy-and-test:
    runs-on: ubuntu-22.04
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_AKS_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_AKS_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_AKS_SUBSCRIPTION_ID }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Terraform Init (KV ACI)
        working-directory: deployment-scripts/azure/kv
        run: terraform init

      - name: Terraform Apply
        working-directory: deployment-scripts/azure/kv
        run: |
          terraform apply -auto-approve \
            -var="location=${{ inputs.region }}" \
            -var="kv_image=${{ inputs.kv_image }}"

      - name: Get ACI IP and name
        id: aci
        working-directory: deployment-scripts/azure/kv
        run: |
          IP=$(terraform output -raw aci_ip_address)
          ACI_NAME=$(terraform output -raw aci_name)
          echo "ip=$IP" >> $GITHUB_OUTPUT
          echo "aci_name=$ACI_NAME" >> $GITHUB_OUTPUT
          echo "KV service IP: $IP (name: $ACI_NAME)"

      - name: Get storage key and share name for upload
        id: tf_outputs
        working-directory: deployment-scripts/azure/kv
        run: |
          KEY=$(terraform output -raw storage_primary_key)
          SHARE=$(terraform output -raw file_share_name)
          echo "storage_primary_key=$KEY" >> $GITHUB_OUTPUT
          echo "file_share_name=$SHARE" >> $GITHUB_OUTPUT
          echo "::add-mask::$KEY"

      - name: Generate test delta
        working-directory: ./tools/key-value-service
        run: |
          mkdir -p ./tmp
          ./data_cli.sh format_delta ./data.csv ./tmp/DELTA_0000000000000001
          ls -la ./tmp/

      - name: Upload deltas to file share
        working-directory: deployment-scripts/azure/kv
        env:
          STORAGE_KEY: ${{ steps.tf_outputs.outputs.storage_primary_key }}
        run: |
          SA_NAME=$(terraform output -raw storage_account_name)
          echo "::add-mask::$STORAGE_KEY"
          az storage file upload-batch \
            --account-name "$SA_NAME" \
            --account-key "$STORAGE_KEY" \
            --destination "${{ steps.tf_outputs.outputs.file_share_name }}" \
            --destination-path "${{ env.DELTAS_PATH }}" \
            --source "$GITHUB_WORKSPACE/tools/key-value-service/tmp"

      - name: Wait for KV to load data
        run: |
          echo "Waiting 90s for KV service to start and load deltas..."
          sleep 90

      - name: Test getValues API
        run: |
          # Query protocol: PUT /v2/getvalues with JSON body (see https://github.com/iSPIRT/protected-auction-key-value-service/blob/main/docs/testing_the_query_protocol.md)
          # Response: compressionGroups[].content is base64-encoded payload with keyValues
          IP="${{ steps.aci.outputs.ip }}"
          URL="http://${IP}:51052/v2/getvalues"
          BODY='{"metadata":{"hostname":"test.com"},"partitions":[{"id":0,"compressionGroupId":0,"arguments":[{"tags":["structured","groupNames"],"data":["9999999990","9999999991"]},{"tags":["custom","keys"],"data":["9999999990","9999999991"]}]},{"id":1,"compressionGroupId":0,"arguments":[{"tags":["structured","groupNames"],"data":["9999999990","9999999991"]},{"tags":["custom","keys"],"data":["9999999990","9999999991"]}]}]}'
          echo "Request: PUT $URL"
          HTTP_CODE=$(curl -s -o /tmp/getvalues.json -w "%{http_code}" -X PUT -H "Content-Type: application/json" -d "$BODY" --connect-timeout 10 --max-time 30 "$URL")
          echo "HTTP status: $HTTP_CODE"
          if [ "$HTTP_CODE" != "200" ]; then
            echo "Expected HTTP 200, got $HTTP_CODE"
            cat /tmp/getvalues.json | head -c 500
            exit 1
          fi
          # Response is {"compressionGroups":[{"compressionGroupId":0,"content":"<base64>"},...]} - decode first content and check keys/values
          CONTENT=$(jq -r '.compressionGroups[0].content // empty' /tmp/getvalues.json)
          if [ -z "$CONTENT" ]; then
            echo "Response missing compressionGroups[0].content"
            cat /tmp/getvalues.json | head -c 500
            exit 1
          fi
          DECODED=$(echo "$CONTENT" | base64 -d 2>/dev/null)
          if [ -z "$DECODED" ]; then
            echo "Failed to base64-decode content"
            exit 1
          fi
          if ! echo "$DECODED" | grep -q "9999999990"; then
            echo "Decoded content missing key 9999999990"
            echo "$DECODED" | head -c 300
            exit 1
          fi
          if ! echo "$DECODED" | grep -q "PLATINUM_CARD\|60000"; then
            echo "Decoded content missing expected value (PLATINUM_CARD|60000)"
            echo "$DECODED" | head -c 300
            exit 1
          fi
          echo "getValues test passed: PUT /v2/getvalues returned 200, compressionGroups[0].content decodes to expected keys and values."

      - name: Get container logs
        if: always()
        working-directory: deployment-scripts/azure/kv
        run: |
          echo "=== KV container logs (including if container terminated) ==="
          RG=$(terraform output -raw resource_group_name 2>/dev/null) || true
          if [ -n "$RG" ]; then
            az container logs \
              --resource-group "$RG" \
              --name "${{ steps.aci.outputs.aci_name }}" \
              --tail 500 \
              || true
          else
            echo "Could not get resource group name (Terraform state may be gone)."
          fi

      - name: Empty share dirs before destroy
        if: always()
        working-directory: deployment-scripts/azure/kv
        env:
          STORAGE_KEY: ${{ steps.tf_outputs.outputs.storage_primary_key }}
          SHARE: ${{ steps.tf_outputs.outputs.file_share_name }}
        run: |
          if [ -z "$STORAGE_KEY" ] || [ -z "$SHARE" ]; then
            echo "Skipping (no storage key or share name from Terraform output)."
            exit 0
          fi
          SA_NAME=$(terraform output -raw storage_account_name 2>/dev/null) || true
          [ -z "$SA_NAME" ] && echo "Skipping (no Terraform state)." && exit 0
          echo "::add-mask::$STORAGE_KEY"
          for dir in deltas realtime; do
            names=$(az storage file list --share-name "$SHARE" --path "$dir" --account-name "$SA_NAME" --account-key "$STORAGE_KEY" -o tsv --query "[].name" 2>/dev/null) || true
            for name in $names; do
              [ -n "$name" ] && az storage file delete --share-name "$SHARE" --path "$dir/$name" --account-name "$SA_NAME" --account-key "$STORAGE_KEY" || true
            done
          done

      - name: Terraform Destroy (all resources)
        if: always()
        working-directory: deployment-scripts/azure/kv
        run: |
          terraform destroy -auto-approve \
            -var="location=${{ inputs.region }}" \
            -var="kv_image=${{ inputs.kv_image }}" || true
